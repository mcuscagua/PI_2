{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paquetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\pyfolio\\pos.py:27: UserWarning: Module \"zipline.assets\" not found; mutltipliers will not be applied to position notionals.\n",
      "  'Module \"zipline.assets\" not found; mutltipliers will not be applied' +\n",
      "WARNING (theano.configdefaults): g++ not available, if using conda: `conda install m2w64-toolchain`\n",
      "C:\\Anaconda3\\lib\\site-packages\\theano\\configdefaults.py:560: UserWarning: DeprecationWarning: there is no c++ compiler.This is deprecated and with Theano 0.11 a c++ compiler will be mandatory\n",
      "  warnings.warn(\"DeprecationWarning: there is no c++ compiler.\"\n",
      "WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n",
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import read_data as imp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyfolio as pf\n",
    "import matplotlib.pyplot as plt\n",
    "import Alphas101 as Alphas\n",
    "\n",
    "import matplotlib as plt\n",
    "from math import sqrt\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "from statistics import stdev\n",
    "from pylab import plot,show\n",
    "from numpy import vstack,array\n",
    "from numpy.random import rand\n",
    "from scipy.cluster.vq import kmeans,vq\n",
    "from sklearn.cluster import KMeans\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.decomposition import PCA \n",
    "\n",
    "'''Data Prep and Model Evaluation'''\n",
    "from sklearn import preprocessing as pp\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, mean_squared_error\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "import random\n",
    "\n",
    "'''Algos'''\n",
    "import tslearn\n",
    "from tslearn.utils import to_time_series_dataset\n",
    "from tslearn.clustering import KShape, TimeSeriesScalerMeanVariance\n",
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from pyclustering.cluster.kmedoids import kmedoids\n",
    "import scipy.cluster.hierarchy as sch\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from pyclustering.cluster.clarans import clarans;\n",
    "from pyclustering.utils import timedcall;\n",
    "from sklearn import datasets\n",
    "import operator\n",
    "import calendar\n",
    "import itertools as it\n",
    "\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funciones Auxiliares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strategy_kshape(df, n = 252, K = 4):\n",
    "    X = TimeSeriesScalerMeanVariance(mu=0., std=1.).fit_transform(df.T.values)\n",
    "\n",
    "    ks = KShape(n_clusters=K, max_iter=100, n_init=100, verbose=0).fit(X)\n",
    "\n",
    "    index = list(range(len(df.columns)))\n",
    "    columns = ['strategies', 'clusters', 'selection']\n",
    "\n",
    "    results = pd.DataFrame(index=index, columns=columns)\n",
    "\n",
    "    results['clusters'] = ks.labels_\n",
    "    results['strategies'] = df.columns\n",
    "\n",
    "    sharpeclusters = []\n",
    "    dfaux = df.tail(n)\n",
    "    for i in range(results['clusters'].nunique()):\n",
    "        l = results.loc[results['clusters'] == i].index.values.astype(int).tolist()\n",
    "        dfexp = dfaux.pct_change().iloc[:, l].sum(axis=1, skipna=True)\n",
    "        \n",
    "        sharpeclusters.append(pf.timeseries.perf_stats(dfexp)['Sharpe ratio'])\n",
    "    sharpeclusters = np.asanyarray(sharpeclusters)\n",
    "\n",
    "    selection = sharpeclusters.argmax()\n",
    "    cond = results['clusters'] == selection\n",
    "\n",
    "    results['selection'] = np.where(cond, 1, 0)\n",
    "\n",
    "    return results['strategies'][results['selection'] == 1].values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strategy_kmeans(df, n =2520, K =3):\n",
    "\n",
    "    df = df.tail(n)\n",
    "    returns = df.pct_change().mean()\n",
    "    returns = pd.DataFrame(returns)\n",
    "    returns.columns = ['Returns'] \n",
    "    returns['Volatility'] = df.pct_change().std()\n",
    "\n",
    "    #format the data as a numpy array to feed into the K-Means algorithm\n",
    "    data = np.asarray([np.asarray(returns['Returns']),np.asarray(returns['Volatility'])]).T\n",
    "    \n",
    "    n_samples = 1500\n",
    "    random_state = 170\n",
    "\n",
    "    # Number of clusters\n",
    "    kmeans1 = KMeans(n_clusters=K, random_state=random_state)\n",
    "    kmeans1.fit(data)\n",
    "    #y_pred = kmeans1.fit_predict(X) \n",
    "    \n",
    "    results=pd.DataFrame({'Returns': data[:, 0], \n",
    "                       'Volatility': data[:, 1],\n",
    "                       'ClusterkMeans':kmeans1.labels_,\n",
    "                       'strategies': df.columns,\n",
    "                      })\n",
    "    \n",
    "    \n",
    "    sharpeclusters =[] \n",
    "    for i in range(results['ClusterkMeans'].nunique()):\n",
    "    \n",
    "        l = results.loc[results['ClusterkMeans'] == i].index.values.astype(int).tolist()\n",
    "        dfexp=df.pct_change().iloc[: , l].sum(axis = 1, skipna = True)\n",
    "        r = dfexp.mean()\n",
    "        s = stdev(dfexp)\n",
    "    \n",
    "        sharpeclusters.append(r/s)\n",
    "    sharpeclusters = np.asanyarray(sharpeclusters)\n",
    "    \n",
    "    selection = sharpeclusters.argmax()\n",
    "    cond = results['ClusterkMeans'] == selection\n",
    "    results['selection'] = np.where(cond, 1, 0)\n",
    "    \n",
    "    \n",
    "    return results['strategies'][results['selection'] == 1].values.tolist()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TSKmeans - Euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strategy_tskmeans_euclidean (df, n =252, K =4, metric = \"euclidean\"):\n",
    "    \n",
    "    #  metric : {“euclidean”, “dtw”, “softdtw”} (default: “euclidean”)\n",
    "    \n",
    "    X = TimeSeriesScalerMeanVariance(mu=0., std=1.).fit_transform(df.T.values)\n",
    "\n",
    "    \n",
    "    \n",
    "    km = TimeSeriesKMeans(n_clusters=4, max_iter=200, n_init=200,tol = 1e-8, \\\n",
    "                      metric= metric, verbose=1, random_state=2019).fit(X)\n",
    "\n",
    "    index = list(range(len(df.columns)))\n",
    "    columns = ['strategies', 'clusters', 'selection']\n",
    "\n",
    "    results = pd.DataFrame(index=index, columns=columns)\n",
    "\n",
    "    results['clusters'] = km.labels_\n",
    "    results['strategies'] = df.columns\n",
    "\n",
    "    sharpeclusters = []\n",
    "    dfaux = df.tail(n)\n",
    "    for i in range(results['clusters'].nunique()):\n",
    "        l = results.loc[results['clusters'] == i].index.values.astype(int).tolist()\n",
    "        dfexp = dfaux.pct_change().iloc[:, l].sum(axis=1, skipna=True)\n",
    "        r = dfexp.mean()\n",
    "        s = stdev(dfexp)\n",
    "\n",
    "        sharpeclusters.append(r / s)\n",
    "    sharpeclusters = np.asanyarray(sharpeclusters)\n",
    "\n",
    "    selection = sharpeclusters.argmax()\n",
    "    cond = results['clusters'] == selection\n",
    "\n",
    "    results['selection'] = np.where(cond, 1, 0)\n",
    "\n",
    "    return results['strategies'][results['selection'] == 1].values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TSKmeans - dtw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strategy_tskmeans_dtw (df, n =252, K =4, metric = \"dtw\"):\n",
    "    \n",
    "    #  metric : {“euclidean”, “dtw”, “softdtw”} (default: “euclidean”)\n",
    "    \n",
    "    X = TimeSeriesScalerMeanVariance(mu=0., std=1.).fit_transform(df.T.values)\n",
    "\n",
    "    \n",
    "    \n",
    "    km = TimeSeriesKMeans(n_clusters=4, max_iter=200, n_init=200,tol = 1e-8, \\\n",
    "                      metric= metric, verbose=1, random_state=2019).fit(X)\n",
    "\n",
    "    index = list(range(len(df.columns)))\n",
    "    columns = ['strategies', 'clusters', 'selection']\n",
    "\n",
    "    results = pd.DataFrame(index=index, columns=columns)\n",
    "\n",
    "    results['clusters'] = km.labels_\n",
    "    results['strategies'] = df.columns\n",
    "\n",
    "    sharpeclusters = []\n",
    "    dfaux = df.tail(n)\n",
    "    for i in range(results['clusters'].nunique()):\n",
    "        l = results.loc[results['clusters'] == i].index.values.astype(int).tolist()\n",
    "        dfexp = dfaux.pct_change().iloc[:, l].sum(axis=1, skipna=True)\n",
    "        r = dfexp.mean()\n",
    "        s = stdev(dfexp)\n",
    "\n",
    "        sharpeclusters.append(r / s)\n",
    "    sharpeclusters = np.asanyarray(sharpeclusters)\n",
    "\n",
    "    selection = sharpeclusters.argmax()\n",
    "    cond = results['clusters'] == selection\n",
    "\n",
    "    results['selection'] = np.where(cond, 1, 0)\n",
    "\n",
    "    return results['strategies'][results['selection'] == 1].values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TSKmeans - softdtw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strategy_tskmeans_softdtw (df, n =252, K =4, metric = \"softdtw\"):\n",
    "    \n",
    "    #  metric : {“euclidean”, “dtw”, “softdtw”} (default: “euclidean”)\n",
    "    \n",
    "    X = TimeSeriesScalerMeanVariance(mu=0., std=1.).fit_transform(df.T.values)\n",
    "\n",
    "    \n",
    "    \n",
    "    km = TimeSeriesKMeans(n_clusters=4, max_iter=200, n_init=200,tol = 1e-8, \\\n",
    "                      metric= metric, verbose=1, random_state=2019).fit(X)\n",
    "\n",
    "    index = list(range(len(df.columns)))\n",
    "    columns = ['strategies', 'clusters', 'selection']\n",
    "\n",
    "    results = pd.DataFrame(index=index, columns=columns)\n",
    "\n",
    "    results['clusters'] = km.labels_\n",
    "    results['strategies'] = df.columns\n",
    "\n",
    "    sharpeclusters = []\n",
    "    dfaux = df.tail(n)\n",
    "    for i in range(results['clusters'].nunique()):\n",
    "        l = results.loc[results['clusters'] == i].index.values.astype(int).tolist()\n",
    "        dfexp = dfaux.pct_change().iloc[:, l].sum(axis=1, skipna=True)\n",
    "        r = dfexp.mean()\n",
    "        s = stdev(dfexp)\n",
    "\n",
    "        sharpeclusters.append(r / s)\n",
    "    sharpeclusters = np.asanyarray(sharpeclusters)\n",
    "\n",
    "    selection = sharpeclusters.argmax()\n",
    "    cond = results['clusters'] == selection\n",
    "\n",
    "    results['selection'] = np.where(cond, 1, 0)\n",
    "\n",
    "    return results['strategies'][results['selection'] == 1].values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clarans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strategy_clarans(df,k=3,v=4, n = 252):\n",
    "    df = df.tail(n)\n",
    "    df3 = df.tail(365).transpose()\n",
    "    data = np.array(df3)\n",
    "\n",
    "    data = data.tolist()\n",
    "\n",
    "    #get a glimpse of dataset\n",
    "    #print(\"A peek into the dataset : \",data[:4])\n",
    "\n",
    "\n",
    "    \"\"\"!\n",
    "    @brief Constructor of clustering algorithm CLARANS.\n",
    "    @details The higher the value of maxneighbor, the closer is CLARANS to K-Medoids, and the longer is each search of a local minima.\n",
    "    @param[in] data: Input data that is presented as list of points (objects), each point should be represented by list or tuple.\n",
    "    @param[in] number_clusters: amount of clusters that should be allocated.\n",
    "    @param[in] numlocal: the number of local minima obtained (amount of iterations for solving the problem).\n",
    "    @param[in] maxneighbor: the maximum number of neighbors examined.        \n",
    "    \"\"\"\n",
    "    clarans_instance = clarans(data, k, 6, v);\n",
    "\n",
    "    #calls the clarans method 'process' to implement the algortihm\n",
    "    (ticks, result) = timedcall(clarans_instance.process);\n",
    "    print(\"Execution time : \", ticks, \"\\n\");\n",
    "\n",
    "    #returns the clusters \n",
    "    clusters = clarans_instance.get_clusters();\n",
    "\n",
    "    #returns the mediods \n",
    "    medoids = clarans_instance.get_medoids();\n",
    "\n",
    "    dic = {}\n",
    "    for var in range(len(clusters)):\n",
    "        for var2 in clusters[var]:\n",
    "            dic[var2] = var\n",
    "\n",
    "\n",
    "    resultado = sorted(dic.items(), key=operator.itemgetter(0))\n",
    "\n",
    "    dic = {}\n",
    "    for var in resultado:\n",
    "        dic[df3.index[var[0]]] = var[1]\n",
    "\n",
    "    clf = pd.DataFrame.from_dict(dic,orient='index')\n",
    "    clf = clf.reset_index()\n",
    "    results = clf.rename(columns={'index':'strategies',0:'clusters'})\n",
    "\n",
    "    sharpeclusters =[] \n",
    "    Features = df\n",
    "    for i in range(results['clusters'].nunique()):\n",
    "\n",
    "        l = results.loc[results['clusters'] == i].index.values.astype(int).tolist()\n",
    "        dfexp=Features.pct_change().iloc[: , l].sum(axis = 1, skipna = True)\n",
    "        r = dfexp.mean()\n",
    "        s = dfexp.std()\n",
    "\n",
    "        sharpeclusters.append(r/s)\n",
    "    sharpeclusters = np.asanyarray(sharpeclusters)\n",
    "\n",
    "    selection = sharpeclusters.argmax()\n",
    "    cond = results['clusters'] == selection\n",
    "\n",
    "    results['selection'] = np.where(cond, 1, 0)\n",
    "\n",
    "    return results['strategies'][results['selection'] == 1].values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kmedoids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strategy_kmedoids(df, n =252, K = 4):\n",
    "\n",
    "    df = df.tail(n)\n",
    "    returns = df.pct_change().mean()\n",
    "    returns = pd.DataFrame(returns)\n",
    "    returns.columns = ['Returns'] \n",
    "    returns['Volatility'] = df.pct_change().std()\n",
    "\n",
    "    data = np.asarray([np.asarray(returns['Returns']),np.asarray(returns['Volatility'])]).T\n",
    "   \n",
    "\n",
    "    initial_medoids = random.sample(range(0,  len(df.columns)), K)\n",
    "    \n",
    "    # Create instance of K-Medoids algorithm.\n",
    "    kmedoids_instance = kmedoids(data, initial_medoids)\n",
    "    # Run cluster analysis and obtain results.\n",
    "    kmedoids_instance.process()\n",
    "    _clusters = kmedoids_instance.get_clusters()\n",
    "\n",
    "    ordered_elements = []\n",
    "    for idx, val in enumerate(_clusters):\n",
    "        for i in val:\n",
    "            ordered_elements.append((i,idx))\n",
    "    \n",
    "    labelsKMedoids = [x[1] for x in sorted(ordered_elements, key=lambda tup: tup[0])]    \n",
    "    \n",
    "\n",
    "    results=pd.DataFrame({'Returns': data[:, 0], \n",
    "                   'Volatility': data[:, 1],\n",
    "                   'ClusterkMedoids':labelsKMedoids,\n",
    "                   'strategies': df.columns,\n",
    "                  })\n",
    "\n",
    "    medoidsclusters =[] \n",
    "\n",
    "    for i in range(results['ClusterkMedoids'].nunique()):\n",
    "        l = results.loc[results['ClusterkMedoids'] == i].index.values.astype(int).tolist()\n",
    "        dfexp=df.pct_change().iloc[: , l].sum(axis = 1, skipna = True)\n",
    "        r = dfexp.mean()\n",
    "        s = stdev(dfexp)\n",
    "\n",
    "        medoidsclusters.append(r/s)\n",
    "    medoidsclusters = np.asanyarray(medoidsclusters)    \n",
    "    selection = medoidsclusters.argmax()\n",
    "\n",
    "    cond = results['ClusterkMedoids'] == selection\n",
    "\n",
    "    results['selection'] = np.where(cond, 1, 0)    \n",
    "    \n",
    "    return results['strategies'][results['selection'] == 1].values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backtesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ja = pf.timeseries.perf_stats(Est_Returns['LA1'])['Sharpe ratio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Annual return           0.347845\n",
       "Cumulative returns     29.167747\n",
       "Annual volatility       0.666689\n",
       "Sharpe ratio            0.784910\n",
       "Calmar ratio            0.393622\n",
       "Stability               0.947601\n",
       "Max drawdown           -0.883704\n",
       "Omega ratio             1.165883\n",
       "Sortino ratio           1.117264\n",
       "Skew                   -0.096924\n",
       "Kurtosis                9.296679\n",
       "Tail ratio              0.972836\n",
       "Daily value at risk    -0.081918\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Est_Returns['LA1'].mean()/Est_Returns['LA1'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Estrategias = pd.read_csv('Rentabilidad de estrategias base 100.csv')\n",
    "Estrategias.set_index('Date', inplace = True)\n",
    "Estrategias.index = pd.to_datetime(Estrategias.index)\n",
    "\n",
    "Est_Returns = Estrategias.pct_change().fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Initial_Date = pd.to_datetime('2014-01-01')\n",
    "\n",
    "Rebalancing_dates = []\n",
    "curr_month = Initial_Date.month\n",
    "\n",
    "the_start = np.where(Initial_Date == Estrategias.index)[0].tolist()[0]\n",
    "\n",
    "for i in range((the_start+1), len(Estrategias.index)):\n",
    "    if Estrategias.index[i].month != curr_month:\n",
    "        Rebalancing_dates.append(Estrategias.index[i-1])\n",
    "        curr_month = Estrategias.index[i].month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the factors over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Clustering_Returns = pd.DataFrame(index = Estrategias.index[Estrategias.index >= Initial_Date],\n",
    "                                  columns = ['Kshape', 'Kmeans', 'TSKM-E', 'Clarans', 'Kmedoids'])\n",
    "\n",
    "Kshape = []\n",
    "Kmeans = []\n",
    "TSKME = []\n",
    "Clarans = []\n",
    "Kmedoids = []\n",
    "\n",
    "Memory_time_window = 126\n",
    "\n",
    "for i in Estrategias.index[Estrategias.index >= Initial_Date]:\n",
    "            \n",
    "    if i in Rebalancing_dates:\n",
    "        \n",
    "        end = np.where(i == Estrategias.index)[0].tolist()[0]\n",
    "        ini = end - Memory_time_window\n",
    "        \n",
    "        # update Baskets\n",
    "        \n",
    "        Kshape = strategy_kshape(Estrategias.iloc[ini:end,:])\n",
    "        Kmeans = strategy_kmeans(Estrategias.iloc[ini:end,:])\n",
    "        TSKME = strategy_tskmeans_euclidean(Estrategias.iloc[ini:end,:])\n",
    "        Clarans = strategy_clarans(Estrategias.iloc[ini:end,:])\n",
    "        Kmedoids = strategy_kmedoids(Estrategias.iloc[ini:end,:])\n",
    "        \n",
    "        # Return calculus\n",
    "        \n",
    "        Clustering_Returns.loc[i,'Kshape'] = Est_Returns.loc[i,Kshape].sum()\n",
    "        Clustering_Returns.loc[i,'Kmeans'] = Est_Returns.loc[i,Kmeans].sum()\n",
    "        Clustering_Returns.loc[i,'TSKM-E'] = Est_Returns.loc[i,TSKME].sum()\n",
    "        Clustering_Returns.loc[i,'Clarans'] = Est_Returns.loc[i,Clarans].sum()\n",
    "        Clustering_Returns.loc[i,'Kmedoids'] = Est_Returns.loc[i,Kmedoids].sum()\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        Clustering_Returns.loc[i,'Kshape'] = Est_Returns.loc[i,Kshape].sum()\n",
    "        Clustering_Returns.loc[i,'Kmeans'] = Est_Returns.loc[i,Kmeans].sum()\n",
    "        Clustering_Returns.loc[i,'TSKM-E'] = Est_Returns.loc[i,TSKME].sum()\n",
    "        Clustering_Returns.loc[i,'Clarans'] = Est_Returns.loc[i,Clarans].sum()\n",
    "        Clustering_Returns.loc[i,'Kmedoids'] = Est_Returns.loc[i,Kmedoids].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Clustering_Returns = 100 * (Clustering_Returns+1).cumprod()\n",
    "Clustering_Returns.to_csv('Cluster Rent Base 100.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Clustering_Returns.plot(figsize=(15,15))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
